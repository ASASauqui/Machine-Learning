{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Datasets\n",
    "from sklearn.datasets import load_iris, load_digits, load_breast_cancer\n",
    "\n",
    "# Training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First experiment\n",
    "\n",
    "### Randomly divide the data into training (70%) and testing (30%) sets\n",
    "### Generate three classification models: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8240740740740741\n",
      "macro-f1 0.8241827842292786\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>88.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>49.1</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>11.1</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>14.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>83.6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>8.8</td>\n",
       "      <td>57.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1     2     3     4     5     6     7     8     9\n",
       "0  100.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "1    0.0  88.5   0.0   0.0   0.0   0.0   0.0   0.0  11.5   0.0\n",
       "2    0.0  11.3  49.1   9.4   0.0   0.0   0.0   0.0  30.2   0.0\n",
       "3    0.0   0.0   0.0  85.2   0.0   0.0   0.0   1.9  11.1   1.9\n",
       "4    0.0   6.2   0.0   0.0  75.0   0.0   4.2  14.6   0.0   0.0\n",
       "5    0.0   1.8   0.0   3.5   0.0  89.5   1.8   3.5   0.0   0.0\n",
       "6    0.0   0.0   1.7   0.0   0.0   0.0  98.3   0.0   0.0   0.0\n",
       "7    0.0   0.0   0.0   0.0   1.9   0.0   0.0  98.1   0.0   0.0\n",
       "8    0.0   8.2   0.0   4.9   0.0   1.6   0.0   1.6  83.6   0.0\n",
       "9    0.0   1.8   0.0  24.6   1.8   0.0   0.0   5.3   8.8  57.9"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,Y = load_digits(return_X_y=True)\n",
    "data = load_digits()\n",
    "\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.30, random_state=0)\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(Xtrain, Ytrain)\n",
    "Ypred = model.predict(Xtest)\n",
    "\n",
    "print('accuracy:', accuracy_score(Ytest,Ypred))\n",
    "print('macro-f1', f1_score(Ytest,Ypred,average='macro'))\n",
    "\n",
    "m =  confusion_matrix(Ytest,Ypred)\n",
    "\n",
    "m = m.transpose()\n",
    "m = np.round( (m / np.sum(m,axis=0))*100,1).transpose() # Valores como porcentajes en lugar de frecuencias\n",
    "df = pandas.DataFrame(m, index=data.target_names, columns=data.target_names)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9555555555555556\n",
      "macro-f1 0.9570516755557739\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>92.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>94.3</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.7</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.5</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>96.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1     2     3     4     5     6     7     8     9\n",
       "0  100.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "1    0.0  92.3   0.0   0.0   0.0   0.0   1.9   0.0   5.8   0.0\n",
       "2    0.0   1.9  94.3   3.8   0.0   0.0   0.0   0.0   0.0   0.0\n",
       "3    0.0   0.0   0.0  98.1   0.0   0.0   0.0   0.0   1.9   0.0\n",
       "4    0.0   0.0   0.0   0.0  97.9   0.0   0.0   2.1   0.0   0.0\n",
       "5    0.0   0.0   0.0   0.0   0.0  94.7   1.8   0.0   0.0   3.5\n",
       "6    0.0   1.7   0.0   0.0   0.0   0.0  98.3   0.0   0.0   0.0\n",
       "7    0.0   0.0   0.0   1.9   1.9   0.0   0.0  96.2   0.0   0.0\n",
       "8    0.0   3.3   1.6   0.0   0.0   0.0   1.6   0.0  88.5   4.9\n",
       "9    0.0   0.0   0.0   0.0   0.0   1.8   0.0   0.0   1.8  96.5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,Y = load_digits(return_X_y=True)\n",
    "data = load_digits()\n",
    "\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.30, random_state=0)\n",
    "\n",
    "model = LogisticRegression(random_state=0, max_iter=100000)\n",
    "model.fit(Xtrain, Ytrain)\n",
    "Ypred = model.predict(Xtest)\n",
    "\n",
    "print('accuracy:', accuracy_score(Ytest,Ypred))\n",
    "print('macro-f1', f1_score(Ytest,Ypred,average='macro'))\n",
    "\n",
    "m =  confusion_matrix(Ytest,Ypred)\n",
    "\n",
    "m = m.transpose()\n",
    "m = np.round( (m / np.sum(m,axis=0))*100,1).transpose() # Valores como porcentajes en lugar de frecuencias\n",
    "df = pandas.DataFrame(m, index=data.target_names, columns=data.target_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8574074074074074\n",
      "macro-f1 0.8591807712816509\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>86.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.1</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>83.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>89.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.9</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>70.5</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.5</td>\n",
       "      <td>84.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3     4     5     6     7     8     9\n",
       "0  93.3   0.0   0.0   0.0   0.0   0.0   2.2   0.0   0.0   4.4\n",
       "1   0.0  86.5   0.0   0.0   3.8   0.0   3.8   1.9   1.9   1.9\n",
       "2   1.9   0.0  81.1   5.7   1.9   0.0   0.0   0.0   3.8   5.7\n",
       "3   0.0   0.0   3.7  83.3   0.0   1.9   3.7   0.0   7.4   0.0\n",
       "4   2.1   0.0   0.0   0.0  89.6   0.0   4.2   0.0   4.2   0.0\n",
       "5   0.0   0.0   1.8   1.8   1.8  89.5   0.0   0.0   0.0   5.3\n",
       "6   0.0   3.3   1.7   0.0   5.0   0.0  90.0   0.0   0.0   0.0\n",
       "7   1.9   1.9   0.0   0.0   0.0   0.0   0.0  92.5   1.9   1.9\n",
       "8   4.9   4.9   3.3   6.6   0.0   0.0   0.0   3.3  70.5   6.6\n",
       "9   0.0   0.0   1.8   5.3   0.0   3.5   0.0   1.8   3.5  84.2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,Y = load_digits(return_X_y=True)\n",
    "data = load_digits()\n",
    "\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.30, random_state=0)\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=0)\n",
    "model.fit(Xtrain, Ytrain)\n",
    "Ypred = model.predict(Xtest)\n",
    "\n",
    "print('accuracy:', accuracy_score(Ytest,Ypred))\n",
    "print('macro-f1', f1_score(Ytest,Ypred,average='macro'))\n",
    "\n",
    "m =  confusion_matrix(Ytest,Ypred)\n",
    "\n",
    "m = m.transpose()\n",
    "m = np.round( (m / np.sum(m,axis=0))*100,1).transpose() # Valores como porcentajes en lugar de frecuencias\n",
    "df = pandas.DataFrame(m, index=data.target_names, columns=data.target_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second experiment\n",
    "\n",
    "### Randomly divide the data into 30 splits using K-fold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "X,Y = load_digits(return_X_y=True)\n",
    "\n",
    "kf = KFold(n_splits=30, random_state=0, shuffle=True)\n",
    "\n",
    "macroF1NB = []\n",
    "macroF1LR = []\n",
    "macroF1DT = []\n",
    "\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "#     print(test_idx)\n",
    "    Xtrain, Ytrain = X[ train_idx,:], Y[train_idx]\n",
    "    Xtest, Ytest = X[ test_idx,:], Y[test_idx]\n",
    "    \n",
    "    # Naive Bayes\n",
    "    model = GaussianNB()\n",
    "    model.fit(Xtrain, Ytrain)\n",
    "    Ypred = model.predict(Xtest)\n",
    "    \n",
    "    macroF1NB.append(f1_score(Ytest,Ypred,average='macro'))\n",
    "    \n",
    "    # Logistic Regression\n",
    "    model = LogisticRegression(random_state=0, max_iter=100000)\n",
    "    model.fit(Xtrain, Ytrain)\n",
    "    Ypred = model.predict(Xtest)\n",
    "    \n",
    "    macroF1LR.append(f1_score(Ytest,Ypred,average='macro'))\n",
    "\n",
    "    # Decision Tree\n",
    "    model = DecisionTreeClassifier(random_state=0)\n",
    "    model.fit(Xtrain, Ytrain)\n",
    "    Ypred = model.predict(Xtest)\n",
    "    \n",
    "    macroF1DT.append(f1_score(Ytest,Ypred,average='macro'))\n",
    "    \n",
    "print('Finish')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Decision Tree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.941424</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.886692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.816835</td>\n",
       "      <td>0.908782</td>\n",
       "      <td>0.819570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.713413</td>\n",
       "      <td>0.965959</td>\n",
       "      <td>0.869921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.806752</td>\n",
       "      <td>0.949451</td>\n",
       "      <td>0.833283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.814630</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.875600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.766420</td>\n",
       "      <td>0.929553</td>\n",
       "      <td>0.860885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.858593</td>\n",
       "      <td>0.988571</td>\n",
       "      <td>0.866031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.858350</td>\n",
       "      <td>0.917893</td>\n",
       "      <td>0.871825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.798931</td>\n",
       "      <td>0.949789</td>\n",
       "      <td>0.871685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.876785</td>\n",
       "      <td>0.922356</td>\n",
       "      <td>0.888095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.844148</td>\n",
       "      <td>0.972071</td>\n",
       "      <td>0.842100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.920159</td>\n",
       "      <td>0.960727</td>\n",
       "      <td>0.812699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.840784</td>\n",
       "      <td>0.932890</td>\n",
       "      <td>0.876297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.788316</td>\n",
       "      <td>0.970784</td>\n",
       "      <td>0.853848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.861688</td>\n",
       "      <td>0.966843</td>\n",
       "      <td>0.826569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.887332</td>\n",
       "      <td>0.971627</td>\n",
       "      <td>0.884743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.840426</td>\n",
       "      <td>0.974603</td>\n",
       "      <td>0.893068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.871140</td>\n",
       "      <td>0.915556</td>\n",
       "      <td>0.826569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.772404</td>\n",
       "      <td>0.952535</td>\n",
       "      <td>0.814288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.896361</td>\n",
       "      <td>0.961029</td>\n",
       "      <td>0.874114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.817807</td>\n",
       "      <td>0.976623</td>\n",
       "      <td>0.852172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.854444</td>\n",
       "      <td>0.978022</td>\n",
       "      <td>0.807929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.865983</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.796634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.868150</td>\n",
       "      <td>0.939764</td>\n",
       "      <td>0.850394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.830242</td>\n",
       "      <td>0.936349</td>\n",
       "      <td>0.887381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.780028</td>\n",
       "      <td>0.959048</td>\n",
       "      <td>0.845588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.787612</td>\n",
       "      <td>0.983007</td>\n",
       "      <td>0.867866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.791303</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.862928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.785328</td>\n",
       "      <td>0.985027</td>\n",
       "      <td>0.810417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.864167</td>\n",
       "      <td>0.970507</td>\n",
       "      <td>0.816541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Naive Bayes  Logistic Regression  Decision Tree\n",
       "0      0.941424             1.000000       0.886692\n",
       "1      0.816835             0.908782       0.819570\n",
       "2      0.713413             0.965959       0.869921\n",
       "3      0.806752             0.949451       0.833283\n",
       "4      0.814630             1.000000       0.875600\n",
       "5      0.766420             0.929553       0.860885\n",
       "6      0.858593             0.988571       0.866031\n",
       "7      0.858350             0.917893       0.871825\n",
       "8      0.798931             0.949789       0.871685\n",
       "9      0.876785             0.922356       0.888095\n",
       "10     0.844148             0.972071       0.842100\n",
       "11     0.920159             0.960727       0.812699\n",
       "12     0.840784             0.932890       0.876297\n",
       "13     0.788316             0.970784       0.853848\n",
       "14     0.861688             0.966843       0.826569\n",
       "15     0.887332             0.971627       0.884743\n",
       "16     0.840426             0.974603       0.893068\n",
       "17     0.871140             0.915556       0.826569\n",
       "18     0.772404             0.952535       0.814288\n",
       "19     0.896361             0.961029       0.874114\n",
       "20     0.817807             0.976623       0.852172\n",
       "21     0.854444             0.978022       0.807929\n",
       "22     0.865983             1.000000       0.796634\n",
       "23     0.868150             0.939764       0.850394\n",
       "24     0.830242             0.936349       0.887381\n",
       "25     0.780028             0.959048       0.845588\n",
       "26     0.787612             0.983007       0.867866\n",
       "27     0.791303             1.000000       0.862928\n",
       "28     0.785328             0.985027       0.810417\n",
       "29     0.864167             0.970507       0.816541"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pandas.DataFrame({'Naive Bayes': macroF1NB,\n",
    "                       'Logistic Regression': macroF1LR,\n",
    "                       'Decision Tree': macroF1DT,})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x20f55c2c8e0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "sns.boxplot(data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones\n",
    "\n",
    "En general, el mejor modelo para este tipo de datos es el Logistic Regression, el cual obtuvo una mejor mediana que los dem√°s (0.965 aproximadamente) y, en general, su concentraci√≥n de valores estuvo por encima del 0.94. Su m√≠nimo est√° por encima del 0.90 y su m√°ximo toca el 1.0. Adem√°s, en la matriz de confusi√≥n se puede observar que s√≥lo en la identificaci√≥n de la variable 8 se obtuvo un 88.5% de efectividad, y las dem√°s obtuvieron valores por encima del 90%; en cambio, en los dem√°s modelos se obtuvo una eficacia mucho menor, llegando incluso a un 49.1% de eficacia en la variable 2 en el caso del modelo Naive Bayes, esto por dar un ejemplo m√°s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
